{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQzYGMVl4-1n"
   },
   "source": [
    "# Text Mining -  Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRnI9EF74-1t"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTwyDa3M4-1v"
   },
   "source": [
    "# Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "x0DzGcra4-1x"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import random\n",
    "import chardet\n",
    "import numpy as np\n",
    "import collections\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import en_core_web_sm \n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.tokenize import word_tokenize, regexp_tokenize\n",
    "from sklearn.svm import SVR, SVC, LinearSVC\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from torch.utils.data.dataset import random_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WZ2OPwtS4-10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit_file_clmns: Index(['time_created', 'date_created', 'up_votes', 'down_votes', 'title',\n",
      "       'over_18', 'author', 'subreddit'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scores killed in Pakistan clashes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japan resumes refuelling mission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US presses Egypt on Gaza border</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jump-start economy: Give health care to all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Council of Europe bashes EU&amp;UN terror blacklist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Headline\n",
       "0                Scores killed in Pakistan clashes\n",
       "1                 Japan resumes refuelling mission\n",
       "2                  US presses Egypt on Gaza border\n",
       "3     Jump-start economy: Give health care to all \n",
       "4  Council of Europe bashes EU&UN terror blacklist"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_path = \"data/reddit_worldnews.csv\"\n",
    "reddit_file = pd.read_csv(reddit_path, encoding=\"utf-8\", encoding_errors=\"ignore\")\n",
    "print(\"reddit_file_clmns:\", reddit_file.columns)\n",
    "reddit = pd.DataFrame(reddit_file[\"title\"]).rename(columns={\"title\":\"Headline\"})\n",
    "reddit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irland News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WZ2OPwtS4-10",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ireland_file_clmns: Index(['publish_date', 'headline_category', 'headline_text'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UUP sees possibility of voting Major out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pubs targeted as curbs on smoking are extended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Papers reveal secret links with O'Neill cabinet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Domestic chaos as Italy takes EU presidency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Learning about the star to which we owe life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Headline\n",
       "0         UUP sees possibility of voting Major out\n",
       "1   Pubs targeted as curbs on smoking are extended\n",
       "2  Papers reveal secret links with O'Neill cabinet\n",
       "3      Domestic chaos as Italy takes EU presidency\n",
       "4     Learning about the star to which we owe life"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ireland_path = \"data/ireland-news-headlines.csv\"\n",
    "ireland_file = pd.read_csv(ireland_path, encoding=\"utf-8\", encoding_errors=\"ignore\")\n",
    "print(\"ireland_file_clmns:\", ireland_file.columns)\n",
    "ireland = pd.DataFrame(ireland_file[\"headline_text\"]).rename(columns={\"headline_text\":\"Headline\"})\n",
    "ireland.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ireland[\"Headline\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing \n",
    "# Regular expression used for tokenization\n",
    "pattern = r'''(?x)    \n",
    "(?:[A-Z]\\.)+          \n",
    "|\\w+(?:-\\w+)*         \n",
    "|\\$?\\d+(?:\\.\\d+)?%?   \n",
    "|\\.\\.\\.               \n",
    "|[][.,;\"\\'?():-_`]  \n",
    "'''\n",
    "\n",
    "# Lemmatizer used \n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "def preprocessing(df):\n",
    "    \"\"\"Input: dataframe\n",
    "       Output: preprocessed dataframe\"\"\"\n",
    "    \n",
    "    # Reduce amount of data for quicker training purposes\n",
    "    # Headline = df[\"Headline\"].head(100)\n",
    "        \n",
    "    # Get the stopwords and punctuation\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    punct = list(string.punctuation)\n",
    "    \n",
    "    # Initialize tokenized list of headlines\n",
    "    # Get list of headlines\n",
    "    headlns_lst = df[\"Headline\"].to_list()\n",
    "    \n",
    "    tokenized_lines = []\n",
    "    for headln in headlns_lst:\n",
    "        line = str(headln).strip().lower()\n",
    "        line = regexp_tokenize(line, pattern)\n",
    "        line = [tok for tok in line if tok not in stopwords and tok not in punct and tok.isalpha() and len(tok)>2]\n",
    "        tokenized_lines.append(line)\n",
    "\n",
    "    # Initialize lemmatized list of headlines\n",
    "    final_pp = []\n",
    "    for headln in tokenized_lines:\n",
    "        lemmatized_line = []\n",
    "        for token in headln:\n",
    "            lemma = lemmatizer.lemmatize(token)\n",
    "            lemmatized_line.append(lemma)\n",
    "        final_pp.append(str(lemmatized_line))\n",
    "    pp_df = pd.DataFrame(final_pp, columns=[\"Headline\"])\n",
    "    \n",
    "    return pp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['score', 'killed', 'pakistan', 'clash']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['japan', 'resume', 'refuelling', 'mission']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['press', 'egypt', 'gaza', 'border']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['economy', 'give', 'health', 'care']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['council', 'europe', 'bash', 'terror', 'black...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509231</th>\n",
       "      <td>['heil', 'trump', 'donald', 'trump', 'white', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509232</th>\n",
       "      <td>['people', 'speculating', 'could', 'madeleine'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509233</th>\n",
       "      <td>['professor', 'receives', 'arab', 'researcher'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509234</th>\n",
       "      <td>['nigel', 'farage', 'attack', 'response', 'tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509235</th>\n",
       "      <td>['palestinian', 'wielding', 'knife', 'shot', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509236 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Headline\n",
       "0                ['score', 'killed', 'pakistan', 'clash']\n",
       "1            ['japan', 'resume', 'refuelling', 'mission']\n",
       "2                    ['press', 'egypt', 'gaza', 'border']\n",
       "3                   ['economy', 'give', 'health', 'care']\n",
       "4       ['council', 'europe', 'bash', 'terror', 'black...\n",
       "...                                                   ...\n",
       "509231  ['heil', 'trump', 'donald', 'trump', 'white', ...\n",
       "509232  ['people', 'speculating', 'could', 'madeleine'...\n",
       "509233  ['professor', 'receives', 'arab', 'researcher'...\n",
       "509234  ['nigel', 'farage', 'attack', 'response', 'tru...\n",
       "509235  ['palestinian', 'wielding', 'knife', 'shot', '...\n",
       "\n",
       "[509236 rows x 1 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_pp = preprocessing(reddit)\n",
    "reddit_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['uup', 'see', 'possibility', 'voting', 'major']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['pub', 'targeted', 'curb', 'smoking', 'extend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['paper', 'reveal', 'secret', 'link', 'neill',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['domestic', 'chaos', 'italy', 'take', 'presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['learning', 'star', 'owe', 'life']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611490</th>\n",
       "      <td>['reserve', 'member', 'defence', 'force', 'all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611491</th>\n",
       "      <td>['maureen', 'dowd', 'joe', 'biden', 'crazy', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611492</th>\n",
       "      <td>['andy', 'murray', 'roll', 'back', 'year', 'ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611493</th>\n",
       "      <td>['delta', 'variant', 'could', 'significant', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611494</th>\n",
       "      <td>['gordon', 'brown', 'got', 'give', 'people', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1611495 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Headline\n",
       "0         ['uup', 'see', 'possibility', 'voting', 'major']\n",
       "1        ['pub', 'targeted', 'curb', 'smoking', 'extend...\n",
       "2        ['paper', 'reveal', 'secret', 'link', 'neill',...\n",
       "3        ['domestic', 'chaos', 'italy', 'take', 'presid...\n",
       "4                      ['learning', 'star', 'owe', 'life']\n",
       "...                                                    ...\n",
       "1611490  ['reserve', 'member', 'defence', 'force', 'all...\n",
       "1611491  ['maureen', 'dowd', 'joe', 'biden', 'crazy', '...\n",
       "1611492  ['andy', 'murray', 'roll', 'back', 'year', 'ce...\n",
       "1611493  ['delta', 'variant', 'could', 'significant', '...\n",
       "1611494  ['gordon', 'brown', 'got', 'give', 'people', '...\n",
       "\n",
       "[1611495 rows x 1 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ireland_pp = preprocessing(ireland)\n",
    "ireland_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to use pre-trained embeddings since headlines not enough\n",
    "# Should we cut out randomly some data of the ireland dataset so that we have equal amount or do we want to normalize in the\n",
    "# end the amount of headlines per theme for the amount of data ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeR26J-N4-15"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyDE26-i4-15"
   },
   "source": [
    "## Splitting data into a train and a test set \n",
    "80% for training and 20% for testing.\n",
    "Data is shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = shuffle(reddit_pp, random_state=42)\n",
    "ireland_df = shuffle(ireland_pp, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "9vWDVkRB4-16"
   },
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "train_reddit, test_reddit = train_test_split(reddit_df, test_size=0.20, random_state=42)\n",
    "train_ireland, test_ireland = train_test_split(ireland_df, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZG3nFTa4-18"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwLrjSBV4-18"
   },
   "source": [
    "# Sentence Embeddings"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_a3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
