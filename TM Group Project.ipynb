{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQzYGMVl4-1n"
   },
   "source": [
    "# Text Mining -  Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRnI9EF74-1t"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTwyDa3M4-1v"
   },
   "source": [
    "# Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x0DzGcra4-1x"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import hdbscan\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import umap\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WZ2OPwtS4-10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit_file_clmns: Index(['time_created', 'date_created', 'up_votes', 'down_votes', 'title',\n",
      "       'over_18', 'author', 'subreddit'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scores killed in Pakistan clashes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japan resumes refuelling mission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US presses Egypt on Gaza border</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jump-start economy: Give health care to all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Council of Europe bashes EU&amp;UN terror blacklist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Headline\n",
       "0                Scores killed in Pakistan clashes\n",
       "1                 Japan resumes refuelling mission\n",
       "2                  US presses Egypt on Gaza border\n",
       "3     Jump-start economy: Give health care to all \n",
       "4  Council of Europe bashes EU&UN terror blacklist"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_path = \"data/reddit_worldnews.csv\"\n",
    "reddit_file = pd.read_csv(reddit_path, encoding=\"utf-8\", encoding_errors=\"ignore\")\n",
    "print(\"reddit_file_clmns:\", reddit_file.columns)\n",
    "reddit = pd.DataFrame(reddit_file[\"title\"]).rename(columns={\"title\":\"Headline\"})\n",
    "reddit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irland News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WZ2OPwtS4-10",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ireland_file_clmns: Index(['publish_date', 'headline_category', 'headline_text'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UUP sees possibility of voting Major out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pubs targeted as curbs on smoking are extended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Papers reveal secret links with O'Neill cabinet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Domestic chaos as Italy takes EU presidency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Learning about the star to which we owe life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Headline\n",
       "0         UUP sees possibility of voting Major out\n",
       "1   Pubs targeted as curbs on smoking are extended\n",
       "2  Papers reveal secret links with O'Neill cabinet\n",
       "3      Domestic chaos as Italy takes EU presidency\n",
       "4     Learning about the star to which we owe life"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ireland_path = \"data/ireland-news-headlines.csv\"\n",
    "ireland_file = pd.read_csv(ireland_path, encoding=\"utf-8\", encoding_errors=\"ignore\")\n",
    "print(\"ireland_file_clmns:\", ireland_file.columns)\n",
    "ireland_filtered_date = ireland_file[(ireland_file[\"publish_date\"] >= 20080125) & \n",
    "                                     (ireland_file[\"publish_date\"] <= 20161122)]\n",
    "ireland = pd.DataFrame(ireland_file[\"headline_text\"]).rename(columns={\"headline_text\":\"Headline\"})\n",
    "ireland.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ireland_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing \n",
    "# Regular expression used for tokenization\n",
    "pattern = r'''(?x)    \n",
    "(?:[A-Z]\\.)+          \n",
    "|\\w+(?:-\\w+)*         \n",
    "|\\$?\\d+(?:\\.\\d+)?%?   \n",
    "|\\.\\.\\.               \n",
    "|[][.,;\"\\'?():-_`]  \n",
    "'''\n",
    "\n",
    "# Lemmatizer used \n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "def preprocessing(df):\n",
    "    \"\"\"Input: dataframe\n",
    "       Output: preprocessed dataframe\"\"\"\n",
    "    \n",
    "    # Reduce amount of data for quicker training purposes\n",
    "    # Headline = df[\"Headline\"].head(100)\n",
    "        \n",
    "    # Get the stopwords and punctuation\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    punct = list(string.punctuation)\n",
    "    \n",
    "    # Initialize tokenized list of headlines\n",
    "    # Get list of headlines\n",
    "    headlns_lst = df[\"Headline\"].to_list()\n",
    "    \n",
    "    tokenized_lines = []\n",
    "    for headln in headlns_lst:\n",
    "        line = str(headln).strip().lower()\n",
    "        line = regexp_tokenize(line, pattern)\n",
    "        line = [tok for tok in line if tok not in stopwords and tok not in punct and tok.isalpha() and len(tok)>2]\n",
    "        tokenized_lines.append(line)\n",
    "    \n",
    "    # Initialize lemmatized list of headlines\n",
    "    pp_df = pd.DataFrame(columns = [\"Headline\"])\n",
    "    \n",
    "    lemmatized_lines = [[lemmatizer.lemmatize(token) for token in headln] for headln in tokenized_lines]\n",
    "    line_df = pd.DataFrame({\"Headline\": lemmatized_lines})\n",
    "    pp_df = pp_df.append(line_df, ignore_index=True)\n",
    " \n",
    "    return pp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[score, killed, pakistan, clash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[japan, resume, refuelling, mission]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[press, egypt, gaza, border]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[economy, give, health, care]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[council, europe, bash, terror, blacklist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509231</th>\n",
       "      <td>[heil, trump, donald, trump, white, nationalis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509232</th>\n",
       "      <td>[people, speculating, could, madeleine, mccann]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509233</th>\n",
       "      <td>[professor, receives, arab, researcher, award]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509234</th>\n",
       "      <td>[nigel, farage, attack, response, trump, ambas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509235</th>\n",
       "      <td>[palestinian, wielding, knife, shot, dead, wes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509236 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Headline\n",
       "0                        [score, killed, pakistan, clash]\n",
       "1                    [japan, resume, refuelling, mission]\n",
       "2                            [press, egypt, gaza, border]\n",
       "3                           [economy, give, health, care]\n",
       "4              [council, europe, bash, terror, blacklist]\n",
       "...                                                   ...\n",
       "509231  [heil, trump, donald, trump, white, nationalis...\n",
       "509232    [people, speculating, could, madeleine, mccann]\n",
       "509233     [professor, receives, arab, researcher, award]\n",
       "509234  [nigel, farage, attack, response, trump, ambas...\n",
       "509235  [palestinian, wielding, knife, shot, dead, wes...\n",
       "\n",
       "[509236 rows x 1 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_pp = preprocessing(reddit)\n",
    "reddit_pp\n",
    "t = timeit.timeit(lambda:reddit_pp)\n",
    "print(t)\n",
    "print(reddit_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irland News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[uup, see, possibility, voting, major]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[pub, targeted, curb, smoking, extended]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[paper, reveal, secret, link, neill, cabinet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[domestic, chaos, italy, take, presidency]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[learning, star, owe, life]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611490</th>\n",
       "      <td>[reserve, member, defence, force, allowed, ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611491</th>\n",
       "      <td>[maureen, dowd, joe, biden, crazy, irish, plan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611492</th>\n",
       "      <td>[andy, murray, roll, back, year, centre, court]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611493</th>\n",
       "      <td>[delta, variant, could, significant, damage, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611494</th>\n",
       "      <td>[gordon, brown, got, give, people, message, hope]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1611495 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Headline\n",
       "0                   [uup, see, possibility, voting, major]\n",
       "1                 [pub, targeted, curb, smoking, extended]\n",
       "2            [paper, reveal, secret, link, neill, cabinet]\n",
       "3               [domestic, chaos, italy, take, presidency]\n",
       "4                              [learning, star, owe, life]\n",
       "...                                                    ...\n",
       "1611490  [reserve, member, defence, force, allowed, ser...\n",
       "1611491  [maureen, dowd, joe, biden, crazy, irish, plan...\n",
       "1611492    [andy, murray, roll, back, year, centre, court]\n",
       "1611493  [delta, variant, could, significant, damage, p...\n",
       "1611494  [gordon, brown, got, give, people, message, hope]\n",
       "\n",
       "[1611495 rows x 1 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ireland_pp = preprocessing(ireland)\n",
    "ireland_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwLrjSBV4-18"
   },
   "source": [
    "# Sentence Embeddings\n",
    "\n",
    "We are sentence embeddings by averaging the pre-trained word embeddings from the GoogleNews vectors. These embeddings can be found at https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g. Download the dataset to the directory ```TMproject/data```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the GoogleNews embeddings\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_vector(word2vec_model, doc):\n",
    "    \"\"\"Calculate the mean vector according to a word2vec model for one document/headline\"\"\"\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model]\n",
    "    if len(doc) >= 1:\n",
    "        return sum(word2vec_model[doc])/len(doc)\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def doc_embeddings(dataset):\n",
    "    \"\"\"Calculate the mean vector for all documents in a dataset.\n",
    "    Outputs a dataframe with document and 300 dim vector representation of it.\"\"\"\n",
    "    embeddings_df = pd.DataFrame()\n",
    "\n",
    "    for doc in dataset[\"Headline\"]:\n",
    "        vec = mean_vector(model, doc)\n",
    "        if len(vec) > 0:\n",
    "            vec_df = pd.Series(vec)\n",
    "            doc_df = pd.Series([doc]).append(vec_df, ignore_index = True)\n",
    "            embeddings_df = embeddings_df.append(doc_df, ignore_index=True) \n",
    "    \n",
    "    return embeddings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above defined functions we created headline embeddings for each headline in the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[score, killed, pakistan, clash]</td>\n",
       "      <td>-0.016129</td>\n",
       "      <td>0.087769</td>\n",
       "      <td>0.174744</td>\n",
       "      <td>0.032501</td>\n",
       "      <td>0.062805</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.054245</td>\n",
       "      <td>-0.231934</td>\n",
       "      <td>-0.019043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>-0.065674</td>\n",
       "      <td>-0.117554</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>-0.078674</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>-0.067261</td>\n",
       "      <td>-0.108887</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.077209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[japan, resume, refuelling, mission]</td>\n",
       "      <td>-0.159668</td>\n",
       "      <td>0.098999</td>\n",
       "      <td>0.081258</td>\n",
       "      <td>0.101440</td>\n",
       "      <td>-0.027832</td>\n",
       "      <td>0.044149</td>\n",
       "      <td>-0.012207</td>\n",
       "      <td>-0.201497</td>\n",
       "      <td>0.269694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.073608</td>\n",
       "      <td>-0.049805</td>\n",
       "      <td>0.068034</td>\n",
       "      <td>-0.031067</td>\n",
       "      <td>-0.114746</td>\n",
       "      <td>-0.174072</td>\n",
       "      <td>0.117676</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>-0.007975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[press, egypt, gaza, border]</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>0.138458</td>\n",
       "      <td>-0.059265</td>\n",
       "      <td>0.034424</td>\n",
       "      <td>-0.024048</td>\n",
       "      <td>-0.052673</td>\n",
       "      <td>-0.092682</td>\n",
       "      <td>-0.093994</td>\n",
       "      <td>0.023010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017792</td>\n",
       "      <td>0.044189</td>\n",
       "      <td>-0.009369</td>\n",
       "      <td>-0.029266</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>-0.024078</td>\n",
       "      <td>-0.188660</td>\n",
       "      <td>-0.022461</td>\n",
       "      <td>0.017151</td>\n",
       "      <td>0.098053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[economy, give, health, care]</td>\n",
       "      <td>-0.005249</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.056671</td>\n",
       "      <td>0.016022</td>\n",
       "      <td>-0.035461</td>\n",
       "      <td>0.098572</td>\n",
       "      <td>-0.119873</td>\n",
       "      <td>0.085754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073151</td>\n",
       "      <td>0.017151</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>-0.055221</td>\n",
       "      <td>-0.057190</td>\n",
       "      <td>0.163560</td>\n",
       "      <td>-0.052979</td>\n",
       "      <td>0.052917</td>\n",
       "      <td>0.126587</td>\n",
       "      <td>-0.110962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[council, europe, bash, terror, blacklist]</td>\n",
       "      <td>-0.027258</td>\n",
       "      <td>0.040814</td>\n",
       "      <td>0.126221</td>\n",
       "      <td>0.196533</td>\n",
       "      <td>-0.120996</td>\n",
       "      <td>-0.073096</td>\n",
       "      <td>-0.180078</td>\n",
       "      <td>-0.112744</td>\n",
       "      <td>0.060791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098340</td>\n",
       "      <td>0.071582</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.184985</td>\n",
       "      <td>-0.114307</td>\n",
       "      <td>-0.017651</td>\n",
       "      <td>-0.054053</td>\n",
       "      <td>-0.059961</td>\n",
       "      <td>0.040894</td>\n",
       "      <td>-0.090448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>[president, musharraf, boasted, country, earne...</td>\n",
       "      <td>-0.003353</td>\n",
       "      <td>0.029210</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.071635</td>\n",
       "      <td>0.023311</td>\n",
       "      <td>-0.035470</td>\n",
       "      <td>-0.050380</td>\n",
       "      <td>-0.066982</td>\n",
       "      <td>0.129551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059130</td>\n",
       "      <td>0.033483</td>\n",
       "      <td>-0.121948</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.014195</td>\n",
       "      <td>-0.015163</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>-0.087930</td>\n",
       "      <td>0.078821</td>\n",
       "      <td>0.008942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>[china, president, jintao, answer, question, o...</td>\n",
       "      <td>-0.019923</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-0.037343</td>\n",
       "      <td>0.116455</td>\n",
       "      <td>-0.068034</td>\n",
       "      <td>0.055949</td>\n",
       "      <td>0.027425</td>\n",
       "      <td>-0.093740</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011963</td>\n",
       "      <td>0.024333</td>\n",
       "      <td>-0.017700</td>\n",
       "      <td>-0.014160</td>\n",
       "      <td>0.042623</td>\n",
       "      <td>-0.095327</td>\n",
       "      <td>0.048096</td>\n",
       "      <td>-0.042562</td>\n",
       "      <td>-0.012482</td>\n",
       "      <td>-0.043264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>[submit, positive, news, roadside, bomb, decli...</td>\n",
       "      <td>0.034933</td>\n",
       "      <td>0.080406</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>-0.083014</td>\n",
       "      <td>-0.092378</td>\n",
       "      <td>-0.071119</td>\n",
       "      <td>-0.103663</td>\n",
       "      <td>0.121845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111990</td>\n",
       "      <td>-0.019152</td>\n",
       "      <td>-0.035244</td>\n",
       "      <td>0.056843</td>\n",
       "      <td>-0.060734</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>-0.079612</td>\n",
       "      <td>-0.001825</td>\n",
       "      <td>-0.006447</td>\n",
       "      <td>-0.034307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>[ceasefire, broken, palestinian, time, mortar,...</td>\n",
       "      <td>-0.001872</td>\n",
       "      <td>0.037323</td>\n",
       "      <td>-0.045603</td>\n",
       "      <td>0.161987</td>\n",
       "      <td>0.120870</td>\n",
       "      <td>-0.101603</td>\n",
       "      <td>-0.006897</td>\n",
       "      <td>-0.115102</td>\n",
       "      <td>0.110235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055517</td>\n",
       "      <td>-0.011678</td>\n",
       "      <td>-0.056234</td>\n",
       "      <td>-0.159831</td>\n",
       "      <td>0.039673</td>\n",
       "      <td>0.132039</td>\n",
       "      <td>-0.146637</td>\n",
       "      <td>-0.031263</td>\n",
       "      <td>0.049835</td>\n",
       "      <td>-0.061503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>[military, abuse, rise, mexican, drug, war, se...</td>\n",
       "      <td>-0.053517</td>\n",
       "      <td>0.022949</td>\n",
       "      <td>-0.010480</td>\n",
       "      <td>0.103164</td>\n",
       "      <td>-0.045206</td>\n",
       "      <td>-0.077759</td>\n",
       "      <td>-0.020318</td>\n",
       "      <td>-0.129333</td>\n",
       "      <td>0.063049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111222</td>\n",
       "      <td>-0.023811</td>\n",
       "      <td>-0.012297</td>\n",
       "      <td>0.073382</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.036150</td>\n",
       "      <td>-0.113444</td>\n",
       "      <td>-0.021158</td>\n",
       "      <td>0.072742</td>\n",
       "      <td>0.008949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9985 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0         1         2    \\\n",
       "0                      [score, killed, pakistan, clash] -0.016129  0.087769   \n",
       "1                  [japan, resume, refuelling, mission] -0.159668  0.098999   \n",
       "2                          [press, egypt, gaza, border] -0.023438  0.138458   \n",
       "3                         [economy, give, health, care] -0.005249  0.042480   \n",
       "4            [council, europe, bash, terror, blacklist] -0.027258  0.040814   \n",
       "...                                                 ...       ...       ...   \n",
       "9980  [president, musharraf, boasted, country, earne... -0.003353  0.029210   \n",
       "9981  [china, president, jintao, answer, question, o... -0.019923 -0.001953   \n",
       "9982  [submit, positive, news, roadside, bomb, decli...  0.034933  0.080406   \n",
       "9983  [ceasefire, broken, palestinian, time, mortar,... -0.001872  0.037323   \n",
       "9984  [military, abuse, rise, mexican, drug, war, se... -0.053517  0.022949   \n",
       "\n",
       "           3         4         5         6         7         8         9    \\\n",
       "0     0.174744  0.032501  0.062805  0.018555  0.054245 -0.231934 -0.019043   \n",
       "1     0.081258  0.101440 -0.027832  0.044149 -0.012207 -0.201497  0.269694   \n",
       "2    -0.059265  0.034424 -0.024048 -0.052673 -0.092682 -0.093994  0.023010   \n",
       "3     0.000671  0.056671  0.016022 -0.035461  0.098572 -0.119873  0.085754   \n",
       "4     0.126221  0.196533 -0.120996 -0.073096 -0.180078 -0.112744  0.060791   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9980  0.000122  0.071635  0.023311 -0.035470 -0.050380 -0.066982  0.129551   \n",
       "9981 -0.037343  0.116455 -0.068034  0.055949  0.027425 -0.093740  0.148438   \n",
       "9982  0.004280  0.007933 -0.083014 -0.092378 -0.071119 -0.103663  0.121845   \n",
       "9983 -0.045603  0.161987  0.120870 -0.101603 -0.006897 -0.115102  0.110235   \n",
       "9984 -0.010480  0.103164 -0.045206 -0.077759 -0.020318 -0.129333  0.063049   \n",
       "\n",
       "      ...       291       292       293       294       295       296  \\\n",
       "0     ...  0.011230 -0.065674 -0.117554  0.085938 -0.078674  0.006287   \n",
       "1     ...  0.005534  0.073608 -0.049805  0.068034 -0.031067 -0.114746   \n",
       "2     ...  0.017792  0.044189 -0.009369 -0.029266  0.012695 -0.024078   \n",
       "3     ... -0.073151  0.017151  0.017548 -0.055221 -0.057190  0.163560   \n",
       "4     ...  0.098340  0.071582  0.000366  0.184985 -0.114307 -0.017651   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "9980  ... -0.059130  0.033483 -0.121948 -0.010001 -0.014195 -0.015163   \n",
       "9981  ... -0.011963  0.024333 -0.017700 -0.014160  0.042623 -0.095327   \n",
       "9982  ... -0.111990 -0.019152 -0.035244  0.056843 -0.060734  0.013799   \n",
       "9983  ... -0.055517 -0.011678 -0.056234 -0.159831  0.039673  0.132039   \n",
       "9984  ... -0.111222 -0.023811 -0.012297  0.073382  0.039432  0.036150   \n",
       "\n",
       "           297       298       299       300  \n",
       "0    -0.067261 -0.108887  0.037109  0.077209  \n",
       "1    -0.174072  0.117676  0.026042 -0.007975  \n",
       "2    -0.188660 -0.022461  0.017151  0.098053  \n",
       "3    -0.052979  0.052917  0.126587 -0.110962  \n",
       "4    -0.054053 -0.059961  0.040894 -0.090448  \n",
       "...        ...       ...       ...       ...  \n",
       "9980  0.002241 -0.087930  0.078821  0.008942  \n",
       "9981  0.048096 -0.042562 -0.012482 -0.043264  \n",
       "9982 -0.079612 -0.001825 -0.006447 -0.034307  \n",
       "9983 -0.146637 -0.031263  0.049835 -0.061503  \n",
       "9984 -0.113444 -0.021158  0.072742  0.008949  \n",
       "\n",
       "[9985 rows x 301 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use all the data, not just first 1000 headlines when finalizing process.\n",
    "# Embedding the Reddit headlines\n",
    "reddit_embed = doc_embeddings(reddit_pp[:10000])\n",
    "reddit_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[uup, see, possibility, voting, major]</td>\n",
       "      <td>-0.019440</td>\n",
       "      <td>0.096291</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.111938</td>\n",
       "      <td>-0.122192</td>\n",
       "      <td>0.011169</td>\n",
       "      <td>0.063950</td>\n",
       "      <td>-0.051147</td>\n",
       "      <td>0.126831</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105103</td>\n",
       "      <td>-0.063385</td>\n",
       "      <td>-0.040253</td>\n",
       "      <td>-0.077667</td>\n",
       "      <td>0.060120</td>\n",
       "      <td>-0.015381</td>\n",
       "      <td>-0.030247</td>\n",
       "      <td>-0.026241</td>\n",
       "      <td>0.083755</td>\n",
       "      <td>-0.034698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[pub, targeted, curb, smoking, extended]</td>\n",
       "      <td>-0.083624</td>\n",
       "      <td>0.037817</td>\n",
       "      <td>-0.006555</td>\n",
       "      <td>0.198828</td>\n",
       "      <td>-0.109766</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.002713</td>\n",
       "      <td>-0.003613</td>\n",
       "      <td>0.247559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>0.042723</td>\n",
       "      <td>-0.034412</td>\n",
       "      <td>0.052075</td>\n",
       "      <td>-0.091187</td>\n",
       "      <td>0.059448</td>\n",
       "      <td>0.062207</td>\n",
       "      <td>0.046216</td>\n",
       "      <td>0.077539</td>\n",
       "      <td>-0.031396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[paper, reveal, secret, link, neill, cabinet]</td>\n",
       "      <td>-0.109766</td>\n",
       "      <td>0.024805</td>\n",
       "      <td>-0.097681</td>\n",
       "      <td>-0.043976</td>\n",
       "      <td>-0.031348</td>\n",
       "      <td>0.067725</td>\n",
       "      <td>0.056592</td>\n",
       "      <td>-0.013770</td>\n",
       "      <td>0.245703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072803</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>-0.129858</td>\n",
       "      <td>0.046387</td>\n",
       "      <td>-0.097412</td>\n",
       "      <td>-0.167065</td>\n",
       "      <td>0.065753</td>\n",
       "      <td>-0.116599</td>\n",
       "      <td>-0.008594</td>\n",
       "      <td>0.048206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[domestic, chaos, italy, take, presidency]</td>\n",
       "      <td>-0.069678</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.110767</td>\n",
       "      <td>-0.011865</td>\n",
       "      <td>-0.110742</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>-0.161548</td>\n",
       "      <td>0.070337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104053</td>\n",
       "      <td>-0.004004</td>\n",
       "      <td>-0.069653</td>\n",
       "      <td>0.019873</td>\n",
       "      <td>-0.081329</td>\n",
       "      <td>0.116309</td>\n",
       "      <td>-0.025882</td>\n",
       "      <td>-0.066553</td>\n",
       "      <td>0.028613</td>\n",
       "      <td>0.098199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[learning, star, owe, life]</td>\n",
       "      <td>0.045166</td>\n",
       "      <td>0.118469</td>\n",
       "      <td>0.081787</td>\n",
       "      <td>0.070648</td>\n",
       "      <td>0.093658</td>\n",
       "      <td>0.063385</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>-0.122314</td>\n",
       "      <td>0.066040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059326</td>\n",
       "      <td>0.094330</td>\n",
       "      <td>-0.176895</td>\n",
       "      <td>-0.117706</td>\n",
       "      <td>-0.069595</td>\n",
       "      <td>-0.030823</td>\n",
       "      <td>0.028152</td>\n",
       "      <td>0.034851</td>\n",
       "      <td>-0.002686</td>\n",
       "      <td>0.005997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9934</th>\n",
       "      <td>[mccartan, go, skiing]</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>-0.008057</td>\n",
       "      <td>0.047424</td>\n",
       "      <td>0.116608</td>\n",
       "      <td>0.050537</td>\n",
       "      <td>0.070679</td>\n",
       "      <td>0.130127</td>\n",
       "      <td>-0.220215</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128540</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>-0.232910</td>\n",
       "      <td>0.153809</td>\n",
       "      <td>0.057678</td>\n",
       "      <td>-0.063354</td>\n",
       "      <td>0.211426</td>\n",
       "      <td>0.015137</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>-0.128418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9935</th>\n",
       "      <td>[nine, irish, rumble]</td>\n",
       "      <td>0.036784</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>-0.091268</td>\n",
       "      <td>0.199056</td>\n",
       "      <td>0.092244</td>\n",
       "      <td>-0.156576</td>\n",
       "      <td>-0.145020</td>\n",
       "      <td>-0.089844</td>\n",
       "      <td>0.055339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057780</td>\n",
       "      <td>0.023926</td>\n",
       "      <td>-0.045898</td>\n",
       "      <td>-0.047872</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>-0.098226</td>\n",
       "      <td>-0.120605</td>\n",
       "      <td>-0.029622</td>\n",
       "      <td>-0.050618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9936</th>\n",
       "      <td>[ireland, final, netted]</td>\n",
       "      <td>0.082520</td>\n",
       "      <td>0.021566</td>\n",
       "      <td>-0.117025</td>\n",
       "      <td>0.069010</td>\n",
       "      <td>0.166341</td>\n",
       "      <td>-0.147135</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.139079</td>\n",
       "      <td>0.223633</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002401</td>\n",
       "      <td>-0.119303</td>\n",
       "      <td>0.054255</td>\n",
       "      <td>0.129801</td>\n",
       "      <td>-0.096517</td>\n",
       "      <td>0.080404</td>\n",
       "      <td>-0.016846</td>\n",
       "      <td>-0.254069</td>\n",
       "      <td>-0.087545</td>\n",
       "      <td>-0.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9937</th>\n",
       "      <td>[andrew, savour, scoreline, first, title]</td>\n",
       "      <td>0.022583</td>\n",
       "      <td>0.037354</td>\n",
       "      <td>-0.011261</td>\n",
       "      <td>-0.094971</td>\n",
       "      <td>0.164825</td>\n",
       "      <td>-0.144775</td>\n",
       "      <td>-0.029312</td>\n",
       "      <td>-0.083008</td>\n",
       "      <td>0.135994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034912</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.029236</td>\n",
       "      <td>0.050598</td>\n",
       "      <td>-0.100220</td>\n",
       "      <td>-0.013817</td>\n",
       "      <td>0.065125</td>\n",
       "      <td>-0.207642</td>\n",
       "      <td>-0.078156</td>\n",
       "      <td>-0.059265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9938</th>\n",
       "      <td>[kilcoyne, resign, friday, showdown]</td>\n",
       "      <td>-0.058919</td>\n",
       "      <td>-0.076375</td>\n",
       "      <td>0.116038</td>\n",
       "      <td>-0.017253</td>\n",
       "      <td>-0.026123</td>\n",
       "      <td>-0.071615</td>\n",
       "      <td>-0.116455</td>\n",
       "      <td>-0.158366</td>\n",
       "      <td>0.120443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159180</td>\n",
       "      <td>-0.054362</td>\n",
       "      <td>-0.249919</td>\n",
       "      <td>0.098470</td>\n",
       "      <td>0.029704</td>\n",
       "      <td>0.031901</td>\n",
       "      <td>-0.065918</td>\n",
       "      <td>-0.204590</td>\n",
       "      <td>0.029460</td>\n",
       "      <td>0.093099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9939 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0         1         2    \\\n",
       "0            [uup, see, possibility, voting, major] -0.019440  0.096291   \n",
       "1          [pub, targeted, curb, smoking, extended] -0.083624  0.037817   \n",
       "2     [paper, reveal, secret, link, neill, cabinet] -0.109766  0.024805   \n",
       "3        [domestic, chaos, italy, take, presidency] -0.069678  0.009131   \n",
       "4                       [learning, star, owe, life]  0.045166  0.118469   \n",
       "...                                             ...       ...       ...   \n",
       "9934                         [mccartan, go, skiing]  0.011719 -0.008057   \n",
       "9935                          [nine, irish, rumble]  0.036784  0.011500   \n",
       "9936                       [ireland, final, netted]  0.082520  0.021566   \n",
       "9937      [andrew, savour, scoreline, first, title]  0.022583  0.037354   \n",
       "9938           [kilcoyne, resign, friday, showdown] -0.058919 -0.076375   \n",
       "\n",
       "           3         4         5         6         7         8         9    \\\n",
       "0     0.004242  0.111938 -0.122192  0.011169  0.063950 -0.051147  0.126831   \n",
       "1    -0.006555  0.198828 -0.109766 -0.000049 -0.002713 -0.003613  0.247559   \n",
       "2    -0.097681 -0.043976 -0.031348  0.067725  0.056592 -0.013770  0.245703   \n",
       "3     0.003613  0.110767 -0.011865 -0.110742  0.000977 -0.161548  0.070337   \n",
       "4     0.081787  0.070648  0.093658  0.063385  0.142822 -0.122314  0.066040   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9934  0.047424  0.116608  0.050537  0.070679  0.130127 -0.220215  0.000244   \n",
       "9935 -0.091268  0.199056  0.092244 -0.156576 -0.145020 -0.089844  0.055339   \n",
       "9936 -0.117025  0.069010  0.166341 -0.147135 -0.007812 -0.139079  0.223633   \n",
       "9937 -0.011261 -0.094971  0.164825 -0.144775 -0.029312 -0.083008  0.135994   \n",
       "9938  0.116038 -0.017253 -0.026123 -0.071615 -0.116455 -0.158366  0.120443   \n",
       "\n",
       "      ...       291       292       293       294       295       296  \\\n",
       "0     ... -0.105103 -0.063385 -0.040253 -0.077667  0.060120 -0.015381   \n",
       "1     ...  0.015234  0.042723 -0.034412  0.052075 -0.091187  0.059448   \n",
       "2     ... -0.072803  0.006732 -0.129858  0.046387 -0.097412 -0.167065   \n",
       "3     ... -0.104053 -0.004004 -0.069653  0.019873 -0.081329  0.116309   \n",
       "4     ... -0.059326  0.094330 -0.176895 -0.117706 -0.069595 -0.030823   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "9934  ...  0.128540  0.053711 -0.232910  0.153809  0.057678 -0.063354   \n",
       "9935  ... -0.057780  0.023926 -0.045898 -0.047872  0.020508  0.017578   \n",
       "9936  ... -0.002401 -0.119303  0.054255  0.129801 -0.096517  0.080404   \n",
       "9937  ... -0.034912  0.004997  0.029236  0.050598 -0.100220 -0.013817   \n",
       "9938  ...  0.159180 -0.054362 -0.249919  0.098470  0.029704  0.031901   \n",
       "\n",
       "           297       298       299       300  \n",
       "0    -0.030247 -0.026241  0.083755 -0.034698  \n",
       "1     0.062207  0.046216  0.077539 -0.031396  \n",
       "2     0.065753 -0.116599 -0.008594  0.048206  \n",
       "3    -0.025882 -0.066553  0.028613  0.098199  \n",
       "4     0.028152  0.034851 -0.002686  0.005997  \n",
       "...        ...       ...       ...       ...  \n",
       "9934  0.211426  0.015137  0.201172 -0.128418  \n",
       "9935 -0.098226 -0.120605 -0.029622 -0.050618  \n",
       "9936 -0.016846 -0.254069 -0.087545 -0.000488  \n",
       "9937  0.065125 -0.207642 -0.078156 -0.059265  \n",
       "9938 -0.065918 -0.204590  0.029460  0.093099  \n",
       "\n",
       "[9939 rows x 301 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding the Ireland headlines\n",
    "ireland_embed = doc_embeddings(ireland_pp[:10000])\n",
    "ireland_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeR26J-N4-15"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The headline embeddings are 300 dimensions and so in the process of clustering the headlines we also conduct a dimensionality reduction. We use a UMAP algorithm together with a HDBSCAN clustering method to form hierarchical density based clusters from the word embeddings. \n",
    "\n",
    "The functions defined below, used to generate and optimize the clustering were written by David Borrelli and can be found at [Clustering sentence embeddings to identify intents in short text](https://towardsdatascience.com/clustering-sentence-embeddings-to-identify-intents-in-short-text-48d22d3bf02e)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clusters(sentence_embeddings,\n",
    "                      n_neighbors,\n",
    "                      n_components, \n",
    "                      min_cluster_size,\n",
    "                      random_state = None):\n",
    "    \"\"\"\n",
    "    Generate HDBSCAN cluster object after reducing embedding dimensionality with UMAP\n",
    "    \"\"\"\n",
    "    \n",
    "    umap_embeddings = umap.UMAP(n_neighbors=n_neighbors, \n",
    "                                n_components=n_components, \n",
    "                                metric='cosine', \n",
    "                                # Changed original function to fit the format of our data.\n",
    "                                random_state=random_state).fit_transform(sentence_embeddings.loc[:, 1:].to_numpy())\n",
    "\n",
    "    clusters = hdbscan.HDBSCAN(min_cluster_size = min_cluster_size,\n",
    "                               metric='euclidean', \n",
    "                               cluster_selection_method='eom').fit(umap_embeddings)\n",
    "    \n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def score_clusters(clusters, prob_threshold = 0.05):\n",
    "    \"\"\"\n",
    "    Returns the label count and cost of a given cluster supplied from running hdbscan\n",
    "    \"\"\"\n",
    "    \n",
    "    cluster_labels = clusters.labels_\n",
    "    label_count = len(np.unique(cluster_labels))\n",
    "    total_num = len(clusters.labels_)\n",
    "    cost = (np.count_nonzero(clusters.probabilities_ < prob_threshold)/total_num)\n",
    "    \n",
    "    return label_count, cost\n",
    "\n",
    "\n",
    "def random_search(embeddings, space, num_evals):\n",
    "    \"\"\"\n",
    "    Randomly search hyperparameter space and limited number of times \n",
    "    and return a summary of the results\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(num_evals):\n",
    "        n_neighbors = random.choice(space['n_neighbors'])\n",
    "        n_components = random.choice(space['n_components'])\n",
    "        min_cluster_size = random.choice(space['min_cluster_size'])\n",
    "        \n",
    "        clusters = generate_clusters(embeddings, \n",
    "                                     n_neighbors = n_neighbors, \n",
    "                                     n_components = n_components, \n",
    "                                     min_cluster_size = min_cluster_size, \n",
    "                                     random_state = 42)\n",
    "    \n",
    "        label_count, cost = score_clusters(clusters, prob_threshold = 0.05)\n",
    "                \n",
    "        results.append([i, n_neighbors, n_components, min_cluster_size, \n",
    "                        label_count, cost])\n",
    "    \n",
    "    result_df = pd.DataFrame(results, columns=['run_id', 'n_neighbors', 'n_components', \n",
    "                                               'min_cluster_size', 'label_count', 'cost'])\n",
    "    \n",
    "    return result_df.sort_values(by='cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran a random parameter search to optimize our clusters for each dataset. We looked for a clustering that had a low loss function whilst at the same time no more than 150 clusters. The rational for this limit is discussed in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the search space for the random search\n",
    "space = {\"n_neighbors\": range(5,15),\n",
    "        \"n_components\": range(2,7),\n",
    "        \"min_cluster_size\": range(2,15),\n",
    "        \"random_state\": 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>n_components</th>\n",
       "      <th>min_cluster_size</th>\n",
       "      <th>label_count</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1437</td>\n",
       "      <td>0.239359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1262</td>\n",
       "      <td>0.286630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>728</td>\n",
       "      <td>0.302854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1177</td>\n",
       "      <td>0.311267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>407</td>\n",
       "      <td>0.316074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>108</td>\n",
       "      <td>0.545418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>110</td>\n",
       "      <td>0.546620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>81</td>\n",
       "      <td>0.547021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>108</td>\n",
       "      <td>0.547621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>90</td>\n",
       "      <td>0.548923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    run_id  n_neighbors  n_components  min_cluster_size  label_count      cost\n",
       "76      76           11             2                 2         1437  0.239359\n",
       "11      11            7             3                 2         1262  0.286630\n",
       "97      97           14             2                 3          728  0.302854\n",
       "45      45            9             5                 2         1177  0.311267\n",
       "1        1            5             2                 5          407  0.316074\n",
       "..     ...          ...           ...               ...          ...       ...\n",
       "78      78           13             5                11          108  0.545418\n",
       "31      31           13             6                11          110  0.546620\n",
       "48      48           14             4                14           81  0.547021\n",
       "71      71           13             3                12          108  0.547621\n",
       "90      90           14             3                13           90  0.548923\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Running the random parameter search on the Ireland news\n",
    "reddit_param_search = random_search(embeddings=reddit_embed, space=space, num_evals= 100)\n",
    "reddit_param_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/norahahr/opt/anaconda3/lib/python3.8/site-packages/umap/spectral.py:260: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n",
      "/Users/norahahr/opt/anaconda3/lib/python3.8/site-packages/umap/spectral.py:260: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n",
      "/Users/norahahr/opt/anaconda3/lib/python3.8/site-packages/umap/spectral.py:260: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n",
      "/Users/norahahr/opt/anaconda3/lib/python3.8/site-packages/umap/spectral.py:260: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n",
      "/Users/norahahr/opt/anaconda3/lib/python3.8/site-packages/umap/spectral.py:260: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>n_components</th>\n",
       "      <th>min_cluster_size</th>\n",
       "      <th>label_count</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1398</td>\n",
       "      <td>0.207868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1183</td>\n",
       "      <td>0.216320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1277</td>\n",
       "      <td>0.219439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1371</td>\n",
       "      <td>0.227991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1358</td>\n",
       "      <td>0.238958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>163</td>\n",
       "      <td>0.492001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>163</td>\n",
       "      <td>0.492001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>134</td>\n",
       "      <td>0.503069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>148</td>\n",
       "      <td>0.511722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>143</td>\n",
       "      <td>0.514941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    run_id  n_neighbors  n_components  min_cluster_size  label_count      cost\n",
       "61      61            5             2                 2         1398  0.207868\n",
       "78      78            6             5                 2         1183  0.216320\n",
       "22      22            5             3                 2         1277  0.219439\n",
       "44      44            8             2                 2         1371  0.227991\n",
       "62      62           13             2                 2         1358  0.238958\n",
       "..     ...          ...           ...               ...          ...       ...\n",
       "58      58           14             6                10          163  0.492001\n",
       "8        8           14             6                10          163  0.492001\n",
       "51      51           10             5                13          134  0.503069\n",
       "79      79           14             6                11          148  0.511722\n",
       "48      48           13             4                12          143  0.514941\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the random parameter search on the Ireland news\n",
    "ireland_param_search = random_search(embeddings=ireland_embed, space=space, num_evals= 100)\n",
    "ireland_param_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the optimized cluster model for the Reddit data\n",
    "reddit_clusters = generate_clusters(sentence_embeddings=reddit_embed, \n",
    "                                    n_neighbors=9, \n",
    "                                    n_components=4, \n",
    "                                    min_cluster_size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the optimized cluster model for the Ireland data\n",
    "ireland_clusters = generate_clusters(sentence_embeddings=ireland_embed, \n",
    "                                     n_neighbors=9, \n",
    "                                     n_components=3, \n",
    "                                     min_cluster_size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When labeling the clusters we looked at the 20 most common words in each cluster. Based on these words we derived the theme or topic of that cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_words(embedding, clustering, label, top_words = 20):\n",
    "    \"\"\"Given a list of sentence embeddings and correspoding cluster labels, returns the most frequent words\n",
    "   for a given cluster.\"\"\"\n",
    "    \n",
    "    word_list = []\n",
    "\n",
    "    for n in range(len(embedding)):\n",
    "        if clustering.labels_[n] == label:\n",
    "            word_list.append(embedding.iloc[n][0])\n",
    "\n",
    "    word_counter = Counter(chain.from_iterable(word_list))\n",
    "\n",
    "    return word_counter.most_common(top_words)\n",
    "\n",
    "def clusters_words(embedding, clustering, top_words = 20):\n",
    "    \"\"\"Given a list of sentence embeddings and corresponding cluster labels, returns the most frequent words\n",
    "    for each cluster.\"\"\"\n",
    "    \n",
    "    word_freq_df = pd.DataFrame()\n",
    "    \n",
    "    for n in np.unique(clustering.labels_):\n",
    "        words_df = pd.Series(cluster_words(embedding = embedding, \n",
    "                                          clustering = clustering, \n",
    "                                          label = n, \n",
    "                                          top_words = top_words))\n",
    "        cluster_df = pd.Series(n).append(words_df, ignore_index = True)\n",
    "        word_freq_df = word_freq_df.append(cluster_df, ignore_index=True)\n",
    "        \n",
    "    return word_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>(iraq, 239)</td>\n",
       "      <td>(war, 192)</td>\n",
       "      <td>(say, 171)</td>\n",
       "      <td>(new, 163)</td>\n",
       "      <td>(world, 162)</td>\n",
       "      <td>(china, 155)</td>\n",
       "      <td>(government, 139)</td>\n",
       "      <td>(year, 136)</td>\n",
       "      <td>(israel, 134)</td>\n",
       "      <td>...</td>\n",
       "      <td>(police, 127)</td>\n",
       "      <td>(iran, 119)</td>\n",
       "      <td>(death, 116)</td>\n",
       "      <td>(attack, 115)</td>\n",
       "      <td>(child, 112)</td>\n",
       "      <td>(woman, 112)</td>\n",
       "      <td>(one, 100)</td>\n",
       "      <td>(bush, 100)</td>\n",
       "      <td>(people, 100)</td>\n",
       "      <td>(military, 99)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>(european, 12)</td>\n",
       "      <td>(union, 9)</td>\n",
       "      <td>(commission, 2)</td>\n",
       "      <td>(truth, 2)</td>\n",
       "      <td>(relation, 2)</td>\n",
       "      <td>(freedom, 2)</td>\n",
       "      <td>(information, 2)</td>\n",
       "      <td>(take, 1)</td>\n",
       "      <td>(greece, 1)</td>\n",
       "      <td>...</td>\n",
       "      <td>(environment, 1)</td>\n",
       "      <td>(infringement, 1)</td>\n",
       "      <td>(election, 1)</td>\n",
       "      <td>(observer, 1)</td>\n",
       "      <td>(venezuela, 1)</td>\n",
       "      <td>(aim, 1)</td>\n",
       "      <td>(improve, 1)</td>\n",
       "      <td>(libya, 1)</td>\n",
       "      <td>(sarkozy, 1)</td>\n",
       "      <td>(mediterranean, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(spy, 27)</td>\n",
       "      <td>(german, 12)</td>\n",
       "      <td>(spying, 12)</td>\n",
       "      <td>(russia, 8)</td>\n",
       "      <td>(israel, 8)</td>\n",
       "      <td>(charge, 5)</td>\n",
       "      <td>(raid, 5)</td>\n",
       "      <td>(face, 4)</td>\n",
       "      <td>(accused, 4)</td>\n",
       "      <td>...</td>\n",
       "      <td>(caught, 3)</td>\n",
       "      <td>(scandal, 3)</td>\n",
       "      <td>(government, 3)</td>\n",
       "      <td>(stasi, 3)</td>\n",
       "      <td>(espionage, 3)</td>\n",
       "      <td>(journalist, 3)</td>\n",
       "      <td>(take, 3)</td>\n",
       "      <td>(company, 3)</td>\n",
       "      <td>(deutsche, 3)</td>\n",
       "      <td>(telekom, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>(ship, 23)</td>\n",
       "      <td>(pirate, 22)</td>\n",
       "      <td>(boat, 14)</td>\n",
       "      <td>(gulf, 13)</td>\n",
       "      <td>(fire, 11)</td>\n",
       "      <td>(coast, 10)</td>\n",
       "      <td>(navy, 10)</td>\n",
       "      <td>(warship, 9)</td>\n",
       "      <td>(iranian, 8)</td>\n",
       "      <td>...</td>\n",
       "      <td>(somalia, 7)</td>\n",
       "      <td>(yacht, 7)</td>\n",
       "      <td>(somali, 5)</td>\n",
       "      <td>(lebanon, 4)</td>\n",
       "      <td>(say, 4)</td>\n",
       "      <td>(seize, 4)</td>\n",
       "      <td>(luxury, 4)</td>\n",
       "      <td>(persian, 4)</td>\n",
       "      <td>(may, 4)</td>\n",
       "      <td>(sends, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>(arm, 11)</td>\n",
       "      <td>(ship, 8)</td>\n",
       "      <td>(zimbabwe, 7)</td>\n",
       "      <td>(china, 7)</td>\n",
       "      <td>(chinese, 5)</td>\n",
       "      <td>(weapon, 5)</td>\n",
       "      <td>(shipment, 4)</td>\n",
       "      <td>(south, 3)</td>\n",
       "      <td>(zim, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>(africa, 2)</td>\n",
       "      <td>(african, 2)</td>\n",
       "      <td>(return, 2)</td>\n",
       "      <td>(home, 2)</td>\n",
       "      <td>(head, 2)</td>\n",
       "      <td>(recall, 2)</td>\n",
       "      <td>(recalled, 2)</td>\n",
       "      <td>(pentagon, 1)</td>\n",
       "      <td>(admits, 1)</td>\n",
       "      <td>(mistaken, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>81.0</td>\n",
       "      <td>(torture, 16)</td>\n",
       "      <td>(waterboarding, 9)</td>\n",
       "      <td>(cia, 5)</td>\n",
       "      <td>(bush, 4)</td>\n",
       "      <td>(top, 3)</td>\n",
       "      <td>(white, 2)</td>\n",
       "      <td>(house, 2)</td>\n",
       "      <td>(mccain, 2)</td>\n",
       "      <td>(standing, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>(memo, 2)</td>\n",
       "      <td>(aide, 2)</td>\n",
       "      <td>(pushed, 2)</td>\n",
       "      <td>(guantánamo, 2)</td>\n",
       "      <td>(inside, 2)</td>\n",
       "      <td>(would, 2)</td>\n",
       "      <td>(interrogation, 2)</td>\n",
       "      <td>(mastermind, 2)</td>\n",
       "      <td>(defends, 1)</td>\n",
       "      <td>(use, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>82.0</td>\n",
       "      <td>(court, 11)</td>\n",
       "      <td>(crime, 11)</td>\n",
       "      <td>(war, 9)</td>\n",
       "      <td>(trial, 8)</td>\n",
       "      <td>(prosecutor, 8)</td>\n",
       "      <td>(judge, 7)</td>\n",
       "      <td>(evidence, 5)</td>\n",
       "      <td>(guantanamo, 5)</td>\n",
       "      <td>(detainee, 4)</td>\n",
       "      <td>...</td>\n",
       "      <td>(former, 4)</td>\n",
       "      <td>(tribunal, 4)</td>\n",
       "      <td>(lawyer, 3)</td>\n",
       "      <td>(rendition, 3)</td>\n",
       "      <td>(supreme, 3)</td>\n",
       "      <td>(british, 3)</td>\n",
       "      <td>(clear, 3)</td>\n",
       "      <td>(hearing, 3)</td>\n",
       "      <td>(liable, 3)</td>\n",
       "      <td>(torture, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>83.0</td>\n",
       "      <td>(old, 18)</td>\n",
       "      <td>(year, 13)</td>\n",
       "      <td>(girl, 11)</td>\n",
       "      <td>(pregnant, 3)</td>\n",
       "      <td>(class, 2)</td>\n",
       "      <td>(kid, 2)</td>\n",
       "      <td>(woman, 2)</td>\n",
       "      <td>(boy, 2)</td>\n",
       "      <td>(school, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>(shoplifting, 1)</td>\n",
       "      <td>(smoked, 1)</td>\n",
       "      <td>(salmon, 1)</td>\n",
       "      <td>(city, 1)</td>\n",
       "      <td>(dumber, 1)</td>\n",
       "      <td>(suburban, 1)</td>\n",
       "      <td>(friend, 1)</td>\n",
       "      <td>(fourteen, 1)</td>\n",
       "      <td>(kicked, 1)</td>\n",
       "      <td>(modelling, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>84.0</td>\n",
       "      <td>(cellar, 13)</td>\n",
       "      <td>(austrian, 8)</td>\n",
       "      <td>(child, 7)</td>\n",
       "      <td>(year, 7)</td>\n",
       "      <td>(daughter, 7)</td>\n",
       "      <td>(coma, 6)</td>\n",
       "      <td>(dungeon, 6)</td>\n",
       "      <td>(girl, 5)</td>\n",
       "      <td>(kept, 4)</td>\n",
       "      <td>...</td>\n",
       "      <td>(woman, 4)</td>\n",
       "      <td>(fritzl, 4)</td>\n",
       "      <td>(police, 3)</td>\n",
       "      <td>(find, 3)</td>\n",
       "      <td>(wake, 3)</td>\n",
       "      <td>(inside, 2)</td>\n",
       "      <td>(horror, 2)</td>\n",
       "      <td>(former, 2)</td>\n",
       "      <td>(home, 2)</td>\n",
       "      <td>(six, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>85.0</td>\n",
       "      <td>(child, 14)</td>\n",
       "      <td>(baby, 12)</td>\n",
       "      <td>(mother, 9)</td>\n",
       "      <td>(father, 8)</td>\n",
       "      <td>(woman, 6)</td>\n",
       "      <td>(daughter, 6)</td>\n",
       "      <td>(girl, 4)</td>\n",
       "      <td>(parent, 4)</td>\n",
       "      <td>(india, 4)</td>\n",
       "      <td>...</td>\n",
       "      <td>(born, 3)</td>\n",
       "      <td>(husband, 3)</td>\n",
       "      <td>(doctor, 3)</td>\n",
       "      <td>(year, 3)</td>\n",
       "      <td>(birth, 3)</td>\n",
       "      <td>(right, 3)</td>\n",
       "      <td>(sue, 2)</td>\n",
       "      <td>(day, 2)</td>\n",
       "      <td>(twin, 2)</td>\n",
       "      <td>(couple, 2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0               1                   2                3              4   \\\n",
       "0   -1.0     (iraq, 239)          (war, 192)       (say, 171)     (new, 163)   \n",
       "1    0.0  (european, 12)          (union, 9)  (commission, 2)     (truth, 2)   \n",
       "2    1.0       (spy, 27)        (german, 12)     (spying, 12)    (russia, 8)   \n",
       "3    2.0      (ship, 23)        (pirate, 22)       (boat, 14)     (gulf, 13)   \n",
       "4    3.0       (arm, 11)           (ship, 8)    (zimbabwe, 7)     (china, 7)   \n",
       "..   ...             ...                 ...              ...            ...   \n",
       "82  81.0   (torture, 16)  (waterboarding, 9)         (cia, 5)      (bush, 4)   \n",
       "83  82.0     (court, 11)         (crime, 11)         (war, 9)     (trial, 8)   \n",
       "84  83.0       (old, 18)          (year, 13)       (girl, 11)  (pregnant, 3)   \n",
       "85  84.0    (cellar, 13)       (austrian, 8)       (child, 7)      (year, 7)   \n",
       "86  85.0     (child, 14)          (baby, 12)      (mother, 9)    (father, 8)   \n",
       "\n",
       "                 5              6                  7                8   \\\n",
       "0      (world, 162)   (china, 155)  (government, 139)      (year, 136)   \n",
       "1     (relation, 2)   (freedom, 2)   (information, 2)        (take, 1)   \n",
       "2       (israel, 8)    (charge, 5)          (raid, 5)        (face, 4)   \n",
       "3        (fire, 11)    (coast, 10)         (navy, 10)     (warship, 9)   \n",
       "4      (chinese, 5)    (weapon, 5)      (shipment, 4)       (south, 3)   \n",
       "..              ...            ...                ...              ...   \n",
       "82         (top, 3)     (white, 2)         (house, 2)      (mccain, 2)   \n",
       "83  (prosecutor, 8)     (judge, 7)      (evidence, 5)  (guantanamo, 5)   \n",
       "84       (class, 2)       (kid, 2)         (woman, 2)         (boy, 2)   \n",
       "85    (daughter, 7)      (coma, 6)       (dungeon, 6)        (girl, 5)   \n",
       "86       (woman, 6)  (daughter, 6)          (girl, 4)      (parent, 4)   \n",
       "\n",
       "               9   ...                11                 12               13  \\\n",
       "0   (israel, 134)  ...     (police, 127)        (iran, 119)     (death, 116)   \n",
       "1     (greece, 1)  ...  (environment, 1)  (infringement, 1)    (election, 1)   \n",
       "2    (accused, 4)  ...       (caught, 3)       (scandal, 3)  (government, 3)   \n",
       "3    (iranian, 8)  ...      (somalia, 7)         (yacht, 7)      (somali, 5)   \n",
       "4        (zim, 2)  ...       (africa, 2)       (african, 2)      (return, 2)   \n",
       "..            ...  ...               ...                ...              ...   \n",
       "82  (standing, 2)  ...         (memo, 2)          (aide, 2)      (pushed, 2)   \n",
       "83  (detainee, 4)  ...       (former, 4)      (tribunal, 4)      (lawyer, 3)   \n",
       "84    (school, 2)  ...  (shoplifting, 1)        (smoked, 1)      (salmon, 1)   \n",
       "85      (kept, 4)  ...        (woman, 4)        (fritzl, 4)      (police, 3)   \n",
       "86     (india, 4)  ...         (born, 3)       (husband, 3)      (doctor, 3)   \n",
       "\n",
       "                 14              15               16                  17  \\\n",
       "0     (attack, 115)    (child, 112)     (woman, 112)          (one, 100)   \n",
       "1     (observer, 1)  (venezuela, 1)         (aim, 1)        (improve, 1)   \n",
       "2        (stasi, 3)  (espionage, 3)  (journalist, 3)           (take, 3)   \n",
       "3      (lebanon, 4)        (say, 4)       (seize, 4)         (luxury, 4)   \n",
       "4         (home, 2)       (head, 2)      (recall, 2)       (recalled, 2)   \n",
       "..              ...             ...              ...                 ...   \n",
       "82  (guantánamo, 2)     (inside, 2)       (would, 2)  (interrogation, 2)   \n",
       "83   (rendition, 3)    (supreme, 3)     (british, 3)          (clear, 3)   \n",
       "84        (city, 1)     (dumber, 1)    (suburban, 1)         (friend, 1)   \n",
       "85        (find, 3)       (wake, 3)      (inside, 2)         (horror, 2)   \n",
       "86        (year, 3)      (birth, 3)       (right, 3)            (sue, 2)   \n",
       "\n",
       "                 18             19                  20  \n",
       "0       (bush, 100)  (people, 100)      (military, 99)  \n",
       "1        (libya, 1)   (sarkozy, 1)  (mediterranean, 1)  \n",
       "2      (company, 3)  (deutsche, 3)        (telekom, 3)  \n",
       "3      (persian, 4)       (may, 4)          (sends, 3)  \n",
       "4     (pentagon, 1)    (admits, 1)       (mistaken, 1)  \n",
       "..              ...            ...                 ...  \n",
       "82  (mastermind, 2)   (defends, 1)            (use, 1)  \n",
       "83     (hearing, 3)    (liable, 3)        (torture, 3)  \n",
       "84    (fourteen, 1)    (kicked, 1)      (modelling, 1)  \n",
       "85      (former, 2)      (home, 2)            (six, 2)  \n",
       "86         (day, 2)      (twin, 2)         (couple, 2)  \n",
       "\n",
       "[87 rows x 21 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The top 20 most common words for each cluster in the Reddit dataset\n",
    "reddit_freq = clusters_words(embedding= reddit_embed, clustering=reddit_clusters, top_words = 20)\n",
    "reddit_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>(new, 131)</td>\n",
       "      <td>(man, 123)</td>\n",
       "      <td>(say, 112)</td>\n",
       "      <td>(plan, 92)</td>\n",
       "      <td>(may, 80)</td>\n",
       "      <td>(year, 72)</td>\n",
       "      <td>(woman, 71)</td>\n",
       "      <td>(talk, 70)</td>\n",
       "      <td>(court, 64)</td>\n",
       "      <td>...</td>\n",
       "      <td>(attack, 58)</td>\n",
       "      <td>(pay, 57)</td>\n",
       "      <td>(job, 56)</td>\n",
       "      <td>(seek, 56)</td>\n",
       "      <td>(take, 52)</td>\n",
       "      <td>(get, 52)</td>\n",
       "      <td>(face, 50)</td>\n",
       "      <td>(dublin, 49)</td>\n",
       "      <td>(back, 46)</td>\n",
       "      <td>(make, 46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>(diary, 56)</td>\n",
       "      <td>(irishman, 52)</td>\n",
       "      <td>(irishwoman, 4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(correction, 22)</td>\n",
       "      <td>(clarification, 22)</td>\n",
       "      <td>(oral, 1)</td>\n",
       "      <td>(explanation, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>(eye, 11)</td>\n",
       "      <td>(market, 9)</td>\n",
       "      <td>(report, 9)</td>\n",
       "      <td>(europe, 9)</td>\n",
       "      <td>(nature, 7)</td>\n",
       "      <td>(british, 1)</td>\n",
       "      <td>(industry, 1)</td>\n",
       "      <td>(bearish, 1)</td>\n",
       "      <td>(reverts, 1)</td>\n",
       "      <td>...</td>\n",
       "      <td>(doctrine, 1)</td>\n",
       "      <td>(apple, 1)</td>\n",
       "      <td>(park, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>(people, 47)</td>\n",
       "      <td>(egan, 1)</td>\n",
       "      <td>(die, 1)</td>\n",
       "      <td>(exposure, 1)</td>\n",
       "      <td>(plain, 1)</td>\n",
       "      <td>(need, 1)</td>\n",
       "      <td>(suffering, 1)</td>\n",
       "      <td>(reduced, 1)</td>\n",
       "      <td>(frightful, 1)</td>\n",
       "      <td>...</td>\n",
       "      <td>(later, 1)</td>\n",
       "      <td>(work, 1)</td>\n",
       "      <td>(young, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>126.0</td>\n",
       "      <td>(party, 19)</td>\n",
       "      <td>(clinton, 4)</td>\n",
       "      <td>(election, 4)</td>\n",
       "      <td>(new, 4)</td>\n",
       "      <td>(meet, 3)</td>\n",
       "      <td>(budget, 3)</td>\n",
       "      <td>(late, 3)</td>\n",
       "      <td>(government, 2)</td>\n",
       "      <td>(may, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>(say, 2)</td>\n",
       "      <td>(get, 2)</td>\n",
       "      <td>(proposal, 2)</td>\n",
       "      <td>(date, 2)</td>\n",
       "      <td>(welcome, 2)</td>\n",
       "      <td>(congress, 1)</td>\n",
       "      <td>(leader, 1)</td>\n",
       "      <td>(row, 1)</td>\n",
       "      <td>(prepare, 1)</td>\n",
       "      <td>(possible, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>127.0</td>\n",
       "      <td>(election, 48)</td>\n",
       "      <td>(candidate, 12)</td>\n",
       "      <td>(vote, 5)</td>\n",
       "      <td>(major, 5)</td>\n",
       "      <td>(plan, 5)</td>\n",
       "      <td>(stand, 4)</td>\n",
       "      <td>(new, 3)</td>\n",
       "      <td>(contest, 3)</td>\n",
       "      <td>(spring, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>(italian, 3)</td>\n",
       "      <td>(nomination, 2)</td>\n",
       "      <td>(win, 2)</td>\n",
       "      <td>(elect, 2)</td>\n",
       "      <td>(socialist, 2)</td>\n",
       "      <td>(meet, 2)</td>\n",
       "      <td>(move, 2)</td>\n",
       "      <td>(gonzalez, 2)</td>\n",
       "      <td>(find, 2)</td>\n",
       "      <td>(proposal, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>128.0</td>\n",
       "      <td>(peace, 89)</td>\n",
       "      <td>(process, 27)</td>\n",
       "      <td>(rally, 13)</td>\n",
       "      <td>(must, 7)</td>\n",
       "      <td>(say, 7)</td>\n",
       "      <td>(call, 6)</td>\n",
       "      <td>(new, 5)</td>\n",
       "      <td>(major, 4)</td>\n",
       "      <td>(angolan, 4)</td>\n",
       "      <td>...</td>\n",
       "      <td>(support, 4)</td>\n",
       "      <td>(need, 4)</td>\n",
       "      <td>(hope, 4)</td>\n",
       "      <td>(move, 3)</td>\n",
       "      <td>(bruton, 3)</td>\n",
       "      <td>(violence, 3)</td>\n",
       "      <td>(effort, 3)</td>\n",
       "      <td>(seek, 3)</td>\n",
       "      <td>(set, 3)</td>\n",
       "      <td>(cardinal, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>129.0</td>\n",
       "      <td>(unionist, 16)</td>\n",
       "      <td>(party, 4)</td>\n",
       "      <td>(talk, 4)</td>\n",
       "      <td>(vote, 4)</td>\n",
       "      <td>(major, 3)</td>\n",
       "      <td>(face, 2)</td>\n",
       "      <td>(government, 2)</td>\n",
       "      <td>(china, 2)</td>\n",
       "      <td>(trade, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>(leader, 2)</td>\n",
       "      <td>(london, 2)</td>\n",
       "      <td>(ulster, 2)</td>\n",
       "      <td>(today, 2)</td>\n",
       "      <td>(islamic, 1)</td>\n",
       "      <td>(one, 1)</td>\n",
       "      <td>(lifeline, 1)</td>\n",
       "      <td>(rope, 1)</td>\n",
       "      <td>(hang, 1)</td>\n",
       "      <td>(socialist, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>130.0</td>\n",
       "      <td>(talk, 39)</td>\n",
       "      <td>(report, 16)</td>\n",
       "      <td>(leader, 10)</td>\n",
       "      <td>(issue, 9)</td>\n",
       "      <td>(summit, 9)</td>\n",
       "      <td>(say, 9)</td>\n",
       "      <td>(bruton, 9)</td>\n",
       "      <td>(major, 8)</td>\n",
       "      <td>(call, 8)</td>\n",
       "      <td>...</td>\n",
       "      <td>(end, 6)</td>\n",
       "      <td>(principle, 5)</td>\n",
       "      <td>(hold, 4)</td>\n",
       "      <td>(new, 4)</td>\n",
       "      <td>(plan, 4)</td>\n",
       "      <td>(forum, 4)</td>\n",
       "      <td>(delay, 4)</td>\n",
       "      <td>(still, 4)</td>\n",
       "      <td>(ira, 4)</td>\n",
       "      <td>(want, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                 1                    2                3   \\\n",
       "0     -1.0        (new, 131)           (man, 123)       (say, 112)   \n",
       "1      0.0       (diary, 56)       (irishman, 52)  (irishwoman, 4)   \n",
       "2      1.0  (correction, 22)  (clarification, 22)        (oral, 1)   \n",
       "3      2.0         (eye, 11)          (market, 9)      (report, 9)   \n",
       "4      3.0      (people, 47)            (egan, 1)         (die, 1)   \n",
       "..     ...               ...                  ...              ...   \n",
       "127  126.0       (party, 19)         (clinton, 4)    (election, 4)   \n",
       "128  127.0    (election, 48)      (candidate, 12)        (vote, 5)   \n",
       "129  128.0       (peace, 89)        (process, 27)      (rally, 13)   \n",
       "130  129.0    (unionist, 16)           (party, 4)        (talk, 4)   \n",
       "131  130.0        (talk, 39)         (report, 16)     (leader, 10)   \n",
       "\n",
       "                   4            5             6                7   \\\n",
       "0          (plan, 92)    (may, 80)    (year, 72)      (woman, 71)   \n",
       "1                 NaN          NaN           NaN              NaN   \n",
       "2    (explanation, 1)          NaN           NaN              NaN   \n",
       "3         (europe, 9)  (nature, 7)  (british, 1)    (industry, 1)   \n",
       "4       (exposure, 1)   (plain, 1)     (need, 1)   (suffering, 1)   \n",
       "..                ...          ...           ...              ...   \n",
       "127          (new, 4)    (meet, 3)   (budget, 3)        (late, 3)   \n",
       "128        (major, 5)    (plan, 5)    (stand, 4)         (new, 3)   \n",
       "129         (must, 7)     (say, 7)     (call, 6)         (new, 5)   \n",
       "130         (vote, 4)   (major, 3)     (face, 2)  (government, 2)   \n",
       "131        (issue, 9)  (summit, 9)      (say, 9)      (bruton, 9)   \n",
       "\n",
       "                  8               9   ...             11               12  \\\n",
       "0         (talk, 70)     (court, 64)  ...   (attack, 58)        (pay, 57)   \n",
       "1                NaN             NaN  ...            NaN              NaN   \n",
       "2                NaN             NaN  ...            NaN              NaN   \n",
       "3       (bearish, 1)    (reverts, 1)  ...  (doctrine, 1)       (apple, 1)   \n",
       "4       (reduced, 1)  (frightful, 1)  ...     (later, 1)        (work, 1)   \n",
       "..               ...             ...  ...            ...              ...   \n",
       "127  (government, 2)        (may, 2)  ...       (say, 2)         (get, 2)   \n",
       "128     (contest, 3)     (spring, 3)  ...   (italian, 3)  (nomination, 2)   \n",
       "129       (major, 4)    (angolan, 4)  ...   (support, 4)        (need, 4)   \n",
       "130       (china, 2)      (trade, 2)  ...    (leader, 2)      (london, 2)   \n",
       "131       (major, 8)       (call, 8)  ...       (end, 6)   (principle, 5)   \n",
       "\n",
       "                13          14              15             16             17  \\\n",
       "0        (job, 56)  (seek, 56)      (take, 52)      (get, 52)     (face, 50)   \n",
       "1              NaN         NaN             NaN            NaN            NaN   \n",
       "2              NaN         NaN             NaN            NaN            NaN   \n",
       "3        (park, 1)         NaN             NaN            NaN            NaN   \n",
       "4       (young, 1)         NaN             NaN            NaN            NaN   \n",
       "..             ...         ...             ...            ...            ...   \n",
       "127  (proposal, 2)   (date, 2)    (welcome, 2)  (congress, 1)    (leader, 1)   \n",
       "128       (win, 2)  (elect, 2)  (socialist, 2)      (meet, 2)      (move, 2)   \n",
       "129      (hope, 4)   (move, 3)     (bruton, 3)  (violence, 3)    (effort, 3)   \n",
       "130    (ulster, 2)  (today, 2)    (islamic, 1)       (one, 1)  (lifeline, 1)   \n",
       "131      (hold, 4)    (new, 4)       (plan, 4)     (forum, 4)     (delay, 4)   \n",
       "\n",
       "                18            19              20  \n",
       "0     (dublin, 49)    (back, 46)      (make, 46)  \n",
       "1              NaN           NaN             NaN  \n",
       "2              NaN           NaN             NaN  \n",
       "3              NaN           NaN             NaN  \n",
       "4              NaN           NaN             NaN  \n",
       "..             ...           ...             ...  \n",
       "127       (row, 1)  (prepare, 1)   (possible, 1)  \n",
       "128  (gonzalez, 2)     (find, 2)   (proposal, 2)  \n",
       "129      (seek, 3)      (set, 3)   (cardinal, 2)  \n",
       "130      (rope, 1)     (hang, 1)  (socialist, 1)  \n",
       "131     (still, 4)      (ira, 4)       (want, 3)  \n",
       "\n",
       "[132 rows x 21 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The top 20 most common words in each cluster in the Ireland dataset\n",
    "ireland_freq = clusters_words(embedding= ireland_embed, clustering=ireland_clusters, top_words = 20)\n",
    "ireland_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['christmas', 'road', 'death', 'increased', 'sharply', 'holiday', 'period']\n",
      "['lurgan', 'killing', 'jolt', 'resident', 'festive', 'holiday', 'mood']\n",
      "['wimbledon', 'move']\n",
      "['holiday', 'plan', 'irks', 'isme']\n",
      "['wimbledon', 'move']\n",
      "['wimbledon', 'move']\n",
      "['visit', 'holiday', 'show']\n",
      "['hand', 'holiday']\n",
      "['unidare', 'move']\n",
      "['move', 'park', 'backed']\n",
      "['clough', 'sinton', 'move']\n",
      "['dully', 'move', 'northside']\n",
      "['hindley', 'move', 'considered']\n",
      "['croke', 'park']\n",
      "['saturn', 'move', 'citywest']\n",
      "['platt', 'may', 'return', 'villa', 'park']\n",
      "['licence', 'shelbourne', 'park']\n",
      "['arm', 'park', 'replaced']\n",
      "['navratilova', 'enticed', 'wimbledon', 'grass']\n",
      "['thyne', 'motion', 'move']\n"
     ]
    }
   ],
   "source": [
    "# Some useful functions for exploring the clusters\n",
    "\n",
    "def cluster_size(clusters, label):\n",
    "    \"\"\"Given a clustering and a cluster label, return the size of that cluster\"\"\"\n",
    "    Counter(clusters.labels_)[label]\n",
    "    \n",
    "def get_headlines(clusters, label, embedding, \n",
    "                  number = len(cluster_size(clusters = clusters, label = label))):\n",
    "    \"\"\"Given a clustering, a cluster label, and the corresponding headline embeddings,\n",
    "    return a given number of random preprocessed headlines from the cluster. If the number of headlines\n",
    "    is left unspecified, return all headlines in the cluster\"\"\"\n",
    "    \n",
    "    headlines = []\n",
    "    \n",
    "    for n in range(len(embedding)):\n",
    "        if clusters.labels_[n] == label:\n",
    "            headlines.append(embedding.iloc[n][0])\n",
    "    \n",
    "    return random.sample(headlines, number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZG3nFTa4-18"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_a3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
